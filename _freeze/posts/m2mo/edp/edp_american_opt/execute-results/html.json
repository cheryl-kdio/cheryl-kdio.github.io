{
  "hash": "0553abb616d1d25a38284276f380865b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Finite difference Methods for American Options\"\nsubtitle: \"EDP in finance\"\nauthor:\n  - name: Cheryl KOUADIO\n  - name: Marilene Kougoum\ncategories: [paper,m2mo,edp]\ndate: \"2026-02-08\"\njupyter: python3\n---\n\n\n\n\n\nDans ce TP, on √©tudie des sch√©mas num√©riques permettant d'approcher la solution de l'√©quation de Black-Scholes pour les options am√©ricaines. On considerera en particulier deux cas de payoff pour les options am√©ricaines :\n\n- **payoff 1:** le cas de put standard de payoff $\\phi_1(s) = (K-s)^+$, avec $K$ le prix d'exercice de l'option. Ce payoff est connu pour avoir de bonnes propri√©t√©s de r√©gularit√©, i.e. il est continu et m√™me lipschitzien, ce qui facilite l'analyse num√©rique.\n\n- **payoff 2:** le cas d'un produit de payoff $\\phi_2(s) = K \\mathbf{1}_{\\frac{K}{2} \\leq s \\leq K }$, qui correspond √† une option de type \"cash-or-nothing\" (payoff en cash) avec barri√®re. Ce payoff est plus irr√©gulier, puisqu'il est discontinu, ce qui rend l'analyse num√©rique plus d√©licate.\n\nDans les deux cas, l'EDP correspond √† un syst√®me non lin√©aire d'√©quations aux d√©riv√©es partielles suivant :\n$$\n\\begin{cases}\n\\min \\left( \\frac{\\partial v}{\\partial t} - \\frac{1}{2} \\sigma^2 s^2 \\frac{\\partial^2 v}{\\partial s^2} - r s \\frac{\\partial v}{\\partial s} + r v, v - \\phi \\right) = 0, \\quad (t,s) \\in (0,T) \\times (S_{min}, S_{max}), \\\\\nv(t, S_{min}) = v_l(t), \\quad t \\in (0,T), \\\\\nv(t, S_{max}) = v_r(t) := 0, \\quad t \\in (0,T), \\\\\nv(0,s) = g(s), \\quad s \\in (S_{min}, S_{max}),\n\\end{cases}\n$$\n\nDans le cas du payoff 1, on a $v_l(t) := \\phi(S_{min}) = K - S_{min}$, tandis que dans le cas du payoff 2, on a $v_l(t) := \\phi(S_{min}) = 0$.\n\nCes sch√©mas nous permettront d'obtenir une approximation num√©rique de la fonction de prix d'un put europ√©en $v(t,s)$, avec $t \\in [0,T]$ et $s \\in [S_{min}, S_{max}]$.\n\nLes sch√©mas num√©riques permettant d'approcher cette EDP abord√©s ici sont :\n1. le sch√©ma d'Euler explicite\n2. le sch√©ma d'Euler implicite (et plus g√©n√©ralement pour tout sch√©ma implicite pour les options am√©ricaines), on est conduit √† un systeme non lin√©aire discret √† r√©soudre √† chaque pas de temps, qui √† la forme d'un \"probl√®me d'obstacle\".\n2. On s'int√©ressera √† diverses m√©thodes num√©riques de r√©solution de ce syst√®me, telles que la m√©thode PSOR (projected successive over-relaxation), une m√©thode de type Newton.\n\n\n# M√©thodes num√©riques\n\nNous consid√©rons la grille discr√®te suivante : $h = \\frac{S_{max} - S_{min}}{J + 1}$ et $\\Delta t = \\frac{T}{N}$, avec $J$ et $N$ des entiers positifs, et :\n- $s_j = S_{min} + j h$, pour $j = 0, \\ldots, J + 1$,\n- $t_n = n \\Delta t$, pour $n = 0, \\ldots, N$.\n\nOn cherche une approximation $U_j^n \\approx v(t_n, s_j)$ pour $j = 1, \\ldots, J$ et $n = 0, \\ldots, N$.\nLes sch√©mas aux diff√©rences finies nous permettront de discr√©tiser l'√©quation de Black-Scholes du prix d'un put am√©ricain sur cette grille.\n\n## Explicit Euler Scheme or Euler Forward Scheme\n\nLe sch√©ma d'Euler explicite est un sch√©ma bas√© sur une discr√©tisation explicite en temps. La discr√©tisation de l'EDP est bas√©e sur des approximations centr√©es. D√®s lors, on approxime les d√©riv√©es partielles de la mani√®re suivante :\n\n$$\n\\begin{cases}\nmin(\\frac{U_j^{n+1} - U_j^n}{\\Delta t} - \\frac{1}{2} \\sigma^2 s_j^2 \\frac{U_{j+1}^n - 2 U_j^n + U_{j-1}^n}{h^2} - r s_j \\frac{U_{j+1}^n - U_{j-1}^n}{2 h} + r U_j^n, U^{n+1}_j - \\phi(s_j))= 0, \\quad j = 1, \\ldots, J,\\quad n = 0, \\ldots, N-1. \\\\\nU_0^n = v_l(t_n), \\quad n = 0, \\ldots, N-1. \\\\\nU_{J+1}^n = v_r(t_n), \\quad n = 0, \\ldots, N-1.\n\\end{cases}\n$$\n\nOn peut la r√©√©crire sous la forme matricielle afin d'extraire une solution num√©rique dite explicite :\nSous forma matricielle, le sch√©ma s'√©crit :\n\n$$\n\\begin{cases}\nmin(\\frac{U^{n+1} - U^n}{\\Delta t} +  A U^n + q(t_n), U^{n+1} - g) = 0, \\quad n = 0, \\ldots, N-1, \\\\\nU^0 = (\\phi(s_i))_{1 \\leq i \\leq J},\n\\end{cases}\n$$\n\no√π\n- g est un vecteur de $\\mathbb{R}^J$ d√©fini par $g_j = \\phi(s_j)$ pour $j = 1, \\ldots, J$,\n\n-   $A$ est une matrice carr√©e tridiagonale de taille $J \\times J$.\n    En posant $\\alpha_j = \\frac{\\sigma^2}{2} \\frac{s_j^2}{h^2}$ et $\\beta_j = r \\frac{s_j}{2 h}$, les coefficients de la matrice $A$ sont donn√©s par :\n\n    $$\n    \\begin{cases}\n    A_{j,j-1} = -\\alpha_j + \\beta_j, \\quad j= 2, \\ldots, J, \\\\\n    A_{j,j} = 2\\alpha_j + r, \\quad j = 1, \\ldots, J, \\\\\n    A_{j,j+1} = -\\alpha_j - \\beta_j, \\quad j = 1, \\ldots, J, \\\\\n    \\end{cases}\n    $$\n\n-   $q(t_n)$ un vecteur de $\\mathbb{R}^J$ qui d√©pendent des param√®tres du mod√®le et de la discr√©tisation spatiale donn√© par :\n\n    $$\n    q_j(t_n) =\n    \\begin{cases}\n    (-\\alpha_1 + \\beta_1) U_0^n, \\quad j = 1, \\\\\n    0, \\quad j = 2, \\ldots, J-1, \\\\\n    (-\\alpha_J + \\beta_J) U_{J+1}^n, \\quad j = J.\n    \\end{cases}\n    $$\n\nDe fait, on obtient la relation de r√©currence explicite permettant de calculer $U^{n+1}$ en fonction de $U^n$ :\n\n$$\nU^{n+1} = max(U^n - \\Delta t ( A U^n + q(t_n)), g)), \\quad n = 0, \\ldots, N-1,\n$$\n\n## Implicit Euler Scheme\n\nPour des raisons de stabilit√©, on peut √©galement utiliser un sch√©ma d'Euler implicite, qui est bas√© sur une discr√©tisation implicite en temps.\n\n### Splitting scheme\nUne premi√®re approche est de consid√©rer le \"splitting scheme\", qui consiste √† s√©parer la partie lin√©aire de l'EDP de la partie non lin√©aire :\n(i) On calcule $U^{n+1,(1)}$ tel que $U^{n+1,(1)} - U^n + \\Delta t (A U^{n+1,(1)} + q(t_{n+1})) = 0$,\n(ii) On calcule $U^{n+1}$ tel que $U^{n+1} = max(U^{n+1,(1)}, g)$.\n\n### M√©thodes num√©riques de r√©solution\nUne seconde approche est de consid√©rer un sch√©ma d'Euler implicite \"fully implicit\", qui consiste √† discr√©tiser l'EDP de mani√®re implicite en temps, ce qui conduit √† un syst√®me non lin√©aire √† r√©soudre √† chaque pas de temps :\n$$\\begin{cases}\nmin(\\frac{U^{n+1} - U^n}{\\Delta t} +  A U^{n+1} + q(t_{n+1}), U^{n+1} - g) = 0, \\quad n = 0, \\ldots, N-1, \\\\\nU^0 = (\\phi(s_i))_{1 \\leq i \\leq J}.\n\\end{cases}$$\n\nEn posant $B = I + \\Delta t A$ et $b = U^n - \\Delta t q(t_{n+1})$, le probl√®me se transforme en la r√©solution d'un probl√®me d'obstacle √† chaque pas de temps ou il s'agit de trouver $x \\in \\mathbb{R}^J$ tel que $min(B x - b, x - g) = 0$. De fait, on a recours √† des m√©thodes num√©riques de r√©solution de ce type de probl√®me, telles que la m√©thode PSOR (projected successive over-relaxation) ou une m√©thode de type Newton.\n\n#### PSOR Algorithm\n\nLa m√©thode PSOR est une m√©thode it√©rative de r√©solution de probl√®mes d'obstacle. Elle consiste √† it√©rer sur les composantes du vecteur $x$ en appliquant une relaxation projet√©e.\n\nTout d'abord, on d√©compose la matrice $B$ en une partie triangulaire inf√©rieure $L$, et une partie triangulaire strictement sup√©rieure $U$, de sorte que $B = L + U$. Ensuite, pour un temps fix√© $n$, on cherche √† trouver une solution $x$ du probl√®me d'obstacle en it√©rant sur les composantes du vecteur $x$ au temps fix√© en appliquant la formule suivante :\n$$\nx_j^{(k+1)} = max\\left(g_j, \\frac{\\omega}{B_{j,j}} \\left(b_j - \\sum_{i=1}^{j-1} B_{j,i} x_i^{(k+1)} - \\sum_{i=j+1}^{J} B_{j,i} x_i^{(k)} \\right) + (1 - \\omega) x_j^k \\right) , \\quad j = 1, \\ldots, J,\n$$\n\n\no√π $k$ est l'indice de l'it√©ration. La m√©thode converge vers la solution du probl√®me d'obstacle, et le taux de convergence d√©pend du choix du param√®tre de relaxation, i.e. du choix de la valeur de $\\omega \\in (0,2)$ dans la formule de relaxation.\nLorsque $\\omega = 1$, la m√©thode PSOR correspond √† la m√©thode classique de Gauss-Seidel projet√©e. Lorsque $\\omega \\neq 1$, la m√©thode PSOR peut acc√©l√©rer la convergence, mais le choix optimal de $\\omega$ d√©pend du probl√®me sp√©cifique et peut n√©cessiter une exp√©rimentation.\n\n#### Semi-smooth Newton's method\n\nLa m√©thode de type Newton est une m√©thode it√©rative de r√©solution de probl√®mes non lin√©aires. Elle consiste √† lin√©ariser le probl√®me d'obstacle autour d'une solution approximative $x^{(k)}$ √† chaque it√©ration, et √† r√©soudre le probl√®me lin√©aris√© pour obtenir une nouvelle approximation $x^{(k+1)}$.\n\nOn cherche √† r√©soudre le probl√®me d'obstacle $F(x) = min(B x - b, x - g) = 0$ en it√©rant sur les approximations successives de la solution.\nOn lin√©arise le probl√®me d'obstacle autour de l'approximation $x^{(k)}$ en utilisant la formule de Taylor :\n$$\nF(x) \\approx F(x^{(k)}) + F'(x^{(k)})(x - x^{(k)}),\n$$\n\nOn cherche √† r√©soudre $F(x) = 0$. D√®s lors, √† chaque it√©ration, on r√©sout le probl√®me lin√©aris√© $F'(x^{(k)})(x - x^{(k)}) = -F(x^{(k)})$ pour obtenir une nouvelle approximation $x^{(k+1)}$. La m√©thode de type Newton converge quadratiquement vers la solution du probl√®me d'obstacle, ce qui en fait une m√©thode tr√®s efficace pour r√©soudre ce type de probl√®me.\n\n$F'(x)$ est la matrice jacobienne de $F$ √† l'approximation $x$. La matrice jacobienne de $F$ est donn√©e par :\n$$\nF'(x)_{i,j} := \\begin{cases}\nB_{i,j}, \\quad \\text{si } B x - b < x - g, \\\\\n\\delta_{i,j}, \\quad \\text{sinon}.\n\\end{cases}\n$$\n\n## Higher order schemes\n\nEnfin, nous envisagerons de comparer les sch√©mas d'Euler implicite, les sch√©mas de type Crank-Nicolson, et un sch√©ma d'ordre 2 tel que le BDF2.\n\n# Impl√©mentations\n\nLes diff√©rents sch√©mas num√©riques √©tudi√©s pour l‚Äô√©quation de Black‚ÄìScholes avec option am√©ricaine partagent une structure commune. Nous introduisons donc une classe de base abstraite SchemeBase qui regroupe les param√®tres financiers et num√©riques, la construction de la grille discr√®te, les conditions initiales et aux limites, ainsi que la discr√©tisation spatiale de l‚Äôop√©rateur de Black-Scholes √† travers la matrice\nA et le vecteur\nq(t).\n\nLes sch√©mas sp√©cifiques h√©ritent de cette classe de base et impl√©mentent la m√©thode solve(). En particulier, nous d√©finissons les classes suivantes :\n- `SchemeEE` pour le sch√©ma d'Euler explicite,\n- `SplittingScheme` pour le sch√©ma splitting d'Euler implicite,\n- `SchemeCN` pour le sch√©ma de Crank-Nicolson,\n- `PSOR` pour la m√©thode PSOR,\n- `NewtonSemiSmooth` pour la m√©thode de r√©solution newton semi smooth, et\n- `BdfScheme` pour le schema de r√©solution BDF2.\n\n::: {#fde8478d .cell execution_count=1}\n``` {.python .cell-code}\n# Package imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport numpy.linalg as lng\nfrom scipy.sparse import diags,eye\nfrom abc import ABC, abstractmethod\nimport scipy.stats as stats\nfrom scipy.sparse import csr_matrix as sparse\nfrom scipy.sparse.linalg import spsolve\nimport pandas as pd\nimport time\nimport warnings\nimport numpy.linalg as lng\nfrom tqdm import tqdm\n\nwarnings.filterwarnings(\"ignore\")\n```\n:::\n\n\n::: {#0774d7d9 .cell execution_count=2}\n``` {.python .cell-code}\nclass SchemeBase(ABC):\n    \"\"\"\n    Classe de base pour les sch√©mas num√©riques de l'√©quation de Black-Scholes.\n    \"\"\"\n    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):\n        # Financial parameters\n        self.r = r\n        self.sigma = sigma\n        self.K = K\n        self.T = T\n\n        # Numerical parameters\n        self.N = N\n        self.J = J\n        self.Smin = Smin\n        self.Smax = Smax\n        self.payoff = payoff\n\n        # Grids\n        self.dt = T / N\n        self.h = (Smax - Smin) / (J + 1)\n        self.s = Smin + self.h * np.arange(1, J + 1)\n\n\n        # Operator\n        self.A, self.alpha, self.beta = self._build_matrix_A()\n\n    def phi(self,s):\n        \"\"\"\n        Condition initiale (payoff) pour un put am√©ricain.\n        ùúô(s) = max(K - s, 0) si payoff=1\n             = K si K * 0.5 <= s <= K sinon 0 si payoff=2\n        \"\"\"\n        if self.payoff == 1:\n            return np.maximum(self.K - s, 0)\n        elif self.payoff  == 2:\n            return np.where((self.K * 0.5 <= s) & (s <= self.K), self.K, 0)\n\n    def uleft(self, t):\n        \"\"\"\n        Condition aux limites √† gauche pour un put am√©ricain.\n        u( t, Smin ) = K * exp(-r * t) - S\n        \"\"\"\n        if self.payoff  == 1 :\n            return self.K - self.Smin if self.Smin > 0 else None\n        elif self.payoff  == 2 :\n            return 0.0\n\n\n    def uright(self, t):\n        \"\"\"\n        Condition aux limites √† droite pour un put am√©ricain.\n        u( t, Smax ) = 0\n        \"\"\"\n        return 0.0\n\n    def _build_matrix_A(self):\n        \"\"\"\n        Matrice d'amplification A.\n        \"\"\"\n        alpha = 0.5 * self.sigma**2 * (self.s**2 / self.h**2)\n        beta  = self.r * self.s / (2 * self.h)\n\n        lower = -alpha[1:] + beta[1:]        # sous-diagonale\n        main  = 2 * alpha + self.r            # diagonale principale\n        upper = -alpha[:-1] - beta[:-1]       # sur-diagonale\n\n        A = diags(\n            diagonals=[lower, main, upper],\n            offsets=[-1, 0, 1],\n            shape=(self.J, self.J),\n            format=\"csr\"\n        )\n\n        return A, alpha, beta\n\n\n    def q(self, t):\n        \"\"\"\n        Vecteur des conditions aux limites.\n        \"\"\"\n        y = np.zeros(self.J)\n        y[0]  = (-self.alpha[0] + self.beta[0]) * self.uleft(t)\n        y[-1] = (-self.alpha[-1] - self.beta[-1]) * self.uright(t)\n        return y\n\n    def interpolate(self, Sval, U):\n        \"\"\"\n        Interpolation lin√©aire pour obtenir la valeur approxim√©e d'un put\n        en un point spot Sval donn√©.\n        \"\"\"\n        if Sval <= self.Smin:\n            return self.uleft(self.T)\n        elif Sval >= self.Smax:\n            return self.uright(self.T)\n        else:\n            return np.interp(Sval, self.s, U)\n\n    # Abstract method\n    @abstractmethod\n    def solve(self):\n        \"\"\"\n        M√©thode abstraite de r√©solution du sch√©ma num√©rique.\n        \"\"\"\n        raise NotImplementedError(\"M√©thode solve() √† impl√©menter dans la classe fille\")\n```\n:::\n\n\n::: {#39b0ad94 .cell execution_count=3}\n``` {.python .cell-code}\nclass SchemeEE(SchemeBase):\n    \"\"\"\n    Sch√©ma d'Euler explicite.\n    \"\"\"\n    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):\n        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)\n        self.scheme_name = \"EE\"\n\n    def solve(self):\n        \"\"\"\n        R√©solution du sch√©ma d'Euler explicite.\n        \"\"\"\n        U = self.phi(self.s)\n        g = self.phi(self.s)\n\n        for n in range(self.N):\n            t = n * self.dt\n            U = np.maximum(U - self.dt * (self.A @ U + self.q(t)), g)\n\n        return U,t\n```\n:::\n\n\n::: {#380f7eb2 .cell execution_count=4}\n``` {.python .cell-code}\nclass SplittingScheme(SchemeBase):\n    \"\"\"\n    Sch√©ma d'Euler implicite \"Splitting scheme\".\n    \"\"\"\n    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):\n        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)\n        self.scheme_name = \"EI-AMER-SPLIT\"\n\n    def solve(self):\n        U = self.phi(self.s)\n        g = self.phi(self.s)\n        I = eye(self.J, format=\"csr\")\n\n        for n in range(self.N):\n            t = n * self.dt\n            U = spsolve(I + self.dt * self.A, U - self.dt * self.q(t))\n            U = np.maximum(U, g)\n\n        return U,t\n```\n:::\n\n\n::: {#3311bfee .cell execution_count=5}\n``` {.python .cell-code}\nclass SchemeCN(SchemeBase):\n    \"\"\"\n    Sch√©ma de Crank-Nicolson.\n    \"\"\"\n    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):\n        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)\n        self.scheme_name = \"CN-AMER-SPLIT\"\n\n    def solve(self):\n        U = self.phi(self.s)\n        g = self.phi(self.s)\n        I = eye(self.J, format=\"csr\")\n        factor_minus = I - 0.5 * self.dt * self.A\n        factor_plus = I + 0.5 * self.dt * self.A\n\n        for n in range(self.N):\n            t = n * self.dt\n            U = spsolve(factor_plus, factor_minus@U - self.dt * self.q(t))\n            U = np.maximum(U, g)\n        return U,t\n```\n:::\n\n\n::: {#3cc80206 .cell execution_count=6}\n``` {.python .cell-code}\nclass PSOR(SchemeBase):\n    \"\"\"\n    Sch√©ma PSOR\n    \"\"\"\n\n    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):\n        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)\n        self.scheme_name = \"EI-AMER-PSOR\"\n\n    def solve(self, omega=1, tol=1e-6, max_iter_=100):\n\n        g = self.phi(self.s).copy()\n        I = eye(self.J, format=\"csr\")\n        B = I + self.dt * self.A\n        U = g.copy()\n\n        # Boucle en temps\n        for n in range(self.N):\n\n            t = n * self.dt\n\n            # Second membre f = U^{n+1} + dt * q(t_n)\n            b = U + self.dt * self.q(t)\n\n            # Initialisation PSOR\n            U_new = U.copy()\n\n            # Boucle PSOR\n            for k in range(max_iter_):\n\n                U_old = U_new.copy()\n                # Boucle spatiale\n                for i in range(self.J):\n                    s1 = 0.0\n                    for j in range(i):\n                        s1 += B[i, j] * U_new[j]\n\n                    s2 = 0.0\n                    for j in range(i + 1, self.J):\n                        s2 += B[i, j] * U_old[j]\n\n                    ci = (b[i] - s1 - s2) / B[i, i]\n                    U_new[i] = max(\n                        (1 - omega )* U_old[i] + omega * ci     ,\n                        g[i]\n                    )\n\n                error1 = lng.norm(U_new - U_old)\n                # error2 = lng.norm(np.minimum(B @ U_new - b, U_new - g))\n                # Crit√®re de convergence PSOR\n                if error1 < tol:\n                    break\n            # Passage au temps suivant\n            U = U_new.copy()\n\n        return U, self.T\n```\n:::\n\n\n::: {#8922a532 .cell execution_count=7}\n``` {.python .cell-code}\nclass NewtonSemiSmooth(SchemeBase):\n    \"\"\"\n    Euler implicite + Newton semi-smooth\n    pour option am√©ricaine (probl√®me d'obstacle)\n    \"\"\"\n\n    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):\n        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)\n        self.scheme_name = \"EI-AMER-NEWTON-SS\"\n\n    def solve(self, tol=1e-8, max_iter_=20):\n\n        # Obstacle (payoff)\n        g = self.phi(self.s).copy()\n\n        # Matrice implicite\n        I = eye(self.J, format=\"csr\")\n        B = I + self.dt * self.A\n\n        # Condition terminale\n        U = g.copy()\n\n        for n in range(self.N):\n\n            t = n * self.dt\n            b = U + self.dt * self.q(t)\n            x = U.copy()\n\n            # Boucle Newton semi-smooth\n            for k in range(max_iter_):\n\n                # F(x)\n                Bx_b = B @ x - b\n                x_g  = x - g\n                F = np.minimum(Bx_b, x_g)\n\n                # Test d'arr√™t\n                if lng.norm(F, np.inf) < tol:\n                    break\n\n                # Construction de F'(x) (jacobienne g√©n√©ralis√©e)\n                rows, cols, data = [], [], []\n\n                for i in range(self.J):\n                    if Bx_b[i] <= x_g[i]:\n                        # ligne i de B\n                        row = B.getrow(i)\n                        rows.extend([i] * len(row.indices))\n                        cols.extend(row.indices)\n                        data.extend(row.data)\n                    else:\n                        # ligne i de I\n                        rows.append(i)\n                        cols.append(i)\n                        data.append(1.0)\n\n                DF = sparse((data, (rows, cols)), shape=(self.J, self.J))\n\n                # √âtape de Newton : DF * delta = F\n                delta = spsolve(DF, F)\n\n                # Mise √† jour\n                x = x - delta\n\n            # Passage au temps suivant\n            U = x.copy()\n\n        return U, self.T\n```\n:::\n\n\n::: {#07d47efa .cell execution_count=8}\n``` {.python .cell-code}\nclass BdfScheme(SchemeBase):\n    \"\"\"\n    Sch√©ma BDF2\n    \"\"\"\n\n    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):\n        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)\n        self.scheme_name = \"BDF2-Obstacle-Newton\"\n\n    def solve(self):\n\n        # Obstacle\n        g = self.phi(self.s).copy()\n        I = eye(self.J, format=\"csr\")\n\n        # ---------- Initialisation ----------\n        # U^0\n        U_nm1 = g.copy()\n\n        # U^1 via Euler implicite (avec obstacle)\n        B_euler = I + self.dt * self.A\n        b_euler = U_nm1 + self.dt * self.q(self.dt)\n        U_n = spsolve(B_euler, b_euler)\n        U_n = np.maximum(U_n, g)   # projection autoris√©e uniquement ici (Euler)\n\n        # ---------- Boucle BDF2 ----------\n        for n in range(1, self.N):\n\n            t = (n + 1) * self.dt\n            factor1 = (3.0 / (2.0 * self.dt)) * I + self.A\n            factor2 = (4.0 * U_n - U_nm1) / (2.0 * self.dt) - self.q(t)\n\n            U = spsolve(factor1, factor2)\n            U = np.maximum(U, g)\n\n            U_nm1 = U_n.copy()\n            U_n = U.copy()\n\n        return U, self.T\n```\n:::\n\n\n# R√©sultats des sch√©mas num√©riques\n\n## Euler Explicit Scheme\n\n\nNous √©tudions ici le comportement du sch√©ma d‚ÄôEuler explicite appliqu√© √† l‚Äô√©quation de Black‚ÄìScholes pour une option am√©ricaine de type put. Les simulations sont r√©alis√©es en faisant varier les param√®tres de discr√©tisation spatiale\nJ et temporelle\nN, tout en imposant la contrainte d‚Äôobstacle √† chaque pas de temps.\n\nLes figures pr√©sent√©es correspondent aux cas suivants (pour les deux payoffs consid√©r√©s) :\n\n- N = 20, J = 50\n- N = 20, J = 20\n- N = 50, J = 20\n\n\nPour chaque configuration, le prix num√©rique de l‚Äôoption est compar√© au payoff, et la valeur associ√©e √† la condition de CFL est calcul√©e.\n\n::: {#43215ab6 .cell execution_count=9}\n``` {.python .cell-code}\nr_ = 0.1\nsigma_ = 0.3\nK_ = 100\nT_ = 1\nSmin_ = 50\nSmax_ = 250\nprint(\"Param√®tres financiers:\")\nprint(\"r=%.2f\" %r_, \"sigma=%.2f\" %sigma_, \"K=%.0f\" %K_, \"T=%.0f\" %T_)\n\n# Definition des param√®tres dans un dictionnaire\nparams = dict(\n    r=r_,\n    sigma=sigma_,\n    K=K_,\n    T=T_,\n    N=None, # Valeur √† d√©finir plus tard\n    J=None, # Valeur √† d√©finir plus tard\n    Smin=Smin_,\n    Smax=Smax_\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParam√®tres financiers:\nr=0.10 sigma=0.30 K=100 T=1\n```\n:::\n:::\n\n\n::: {#a196213e .cell execution_count=10}\n``` {.python .cell-code}\nJ_values = [50, 20, 20]\nN_values = [20, 20, 50]\n\ncfl_records1 = []\n\nfig, axes = plt.subplots(1, 3, figsize=(24, 8), sharey=False)\nfor j, (N_, J_) in enumerate(zip(N_values, J_values)):\n    params['N'] = N_\n    params['J'] = J_\n\n    ee = SchemeEE(**params, payoff=1)\n    U, t = ee.solve()\n    s = ee.s\n    dt = ee.dt\n\n    #CFL condition\n    CFL = dt / (ee.h ** 2) * (ee.sigma ** 2) * (ee.Smax ** 2)\n\n    # Enregistrement dans la table\n    cfl_records1.append({\n        \"N\": N_,\n        \"J\": J_,\n        \"CFL\": CFL\n    })\n\n    ax = axes[j]\n    ax.plot(s, U, label=\"Prix option\")\n    ax.plot(s, ee.phi(s), 'k--', label=\"Payoff\")\n\n    ax.set_title(f\"N = {N_}, J = {J_}\")\n    ax.set_xlabel(\"s\")\n    if j == 0:\n        ax.set_ylabel(\"u(t,s)\")\n    ax.legend()\n\nplt.suptitle(\n    f\"Evolution du prix du put am√©ricain -- Scheme {ee.scheme_name}\",\n    fontsize=16\n)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](edp_american_opt_files/figure-html/cell-11-output-1.png){}\n:::\n:::\n\n\n::: {#18523a2c .cell execution_count=11}\n``` {.python .cell-code}\nJ_values = [50, 20, 20]\nN_values = [20, 20, 50]\n\ncfl_records2 = []\n\nfig, axes = plt.subplots(1, 3, figsize=(24, 8), sharey=False)\nfor j, (N_, J_) in enumerate(zip(N_values, J_values)):\n    params['N'] = N_\n    params['J'] = J_\n\n    ee = SchemeEE(**params, payoff=2)\n    U, t = ee.solve()\n    s = ee.s\n    dt = ee.dt\n\n    #CFL condition\n    CFL = dt / (ee.h ** 2) * (ee.sigma ** 2) * (ee.Smax ** 2)\n\n    # Enregistrement dans la table\n    cfl_records2.append({\n        \"N\": N_,\n        \"J\": J_,\n        \"CFL\": CFL\n    })\n\n    ax = axes[j]\n    ax.plot(s, U, label=\"Prix option\")\n    ax.plot(s, ee.phi(s), 'k--', label=\"Payoff\")\n\n    ax.set_title(f\"N = {N_}, J = {J_}\")\n    ax.set_xlabel(\"s\")\n    if j == 0:\n        ax.set_ylabel(\"u(t,s)\")\n    ax.legend()\n\nplt.suptitle(\n    f\"Evolution du prix du put am√©ricain -- Scheme {ee.scheme_name}, N fix√© √† {N_}\",\n    fontsize=16\n)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](edp_american_opt_files/figure-html/cell-12-output-1.png){}\n:::\n:::\n\n\nLes figures ci - dessus repr√©sentent le prix num√©rique de l‚Äôoption au temps final, compar√© au payoff, pour diff√©rentes configurations de maillage.\n\nLes r√©sultats montrent que le comportement du sch√©ma d√©pend fortement du choix de\nN et\nJ. Lorsque le maillage spatial est fin (\nJ=50) et que le nombre de pas de temps est relativement faible (\nN=20), la solution num√©rique devient instable et pr√©sente de fortes oscillations, avec des valeurs non physiques. Ce ph√©nom√®ne traduit une instabilit√© du sch√©ma explicite.\nEn revanche, pour un maillage spatial plus grossier (\nJ=20) et un pas de temps suffisamment petit (\nN=20 ou N=50), la solution obtenue est plus r√©guli√®re et respecte correctement la contrainte d‚Äôoption am√©ricaine, la solution restant au-dessus du payoff.\n\nCes observations sugg√®rent que la stabilit√© du sch√©ma d‚ÄôEuler explicite est √©troitement li√©e √† la relation entre le pas de temps et le pas d‚Äôespace, ce qui motive l‚Äôanalyse de la condition de stabilit√© de type CFL.\n\n::: {#3fc192bc .cell execution_count=12}\n``` {.python .cell-code}\ncfl_df1 = pd.DataFrame(cfl_records1)  # Cas 1 : N fix√©\ncfl_df2 = pd.DataFrame(cfl_records2)  # Cas 2 : N = J\n\ncfl_df1 = cfl_df1.rename(columns={\"CFL\": \"CFL (N=10)\"})\ncfl_df2 = cfl_df2.rename(columns={\"CFL\": \"CFL (N=J)\"})\n\nprint(\"Payoff standard:\")\nprint(\"=\"*20)\nprint(cfl_df1)\nprint(\"Payoff tronqu√©:\")\nprint(\"=\"*20)\nprint(cfl_df2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPayoff standard:\n====================\n    N   J  CFL (N=10)\n0  20  50   18.288281\n1  20  20    3.100781\n2  50  20    1.240312\nPayoff tronqu√©:\n====================\n    N   J  CFL (N=J)\n0  20  50  18.288281\n1  20  20   3.100781\n2  50  20   1.240312\n```\n:::\n:::\n\n\nL‚Äô√©tude de la condition de CFL met en √©vidence le caract√®re conditionnellement stable du sch√©ma d‚ÄôEuler explicite. Comme observ√© sur les figures, lorsque le maillage spatial est raffin√© sans diminution suffisante du pas de temps, la condition de stabilit√© est viol√©e et la solution num√©rique pr√©sente des oscillations marqu√©es. √Ä l‚Äôinverse, lorsque\nN et J sont augment√©s conjointement, la condition de CFL est mieux respect√©e et le comportement du sch√©ma s‚Äôam√©liore.\n\nOn remarque par ailleurs que les valeurs calcul√©es de la CFL sont identiques pour le payoff standard et pour le payoff tronqu√©. Ce r√©sultat est attendu, puisque la condition de stabilit√© d√©pend uniquement des param√®tres num√©riques et du mod√®le, en particulier du pas de temps\nŒît, du pas d‚Äôespace h, de la volatilit√©\nœÉ et de la borne sup√©rieure\nSmax et non de la r√©gularit√© du payoff.\n\n::: {#87861e0d .cell execution_count=13}\n``` {.python .cell-code}\ndef get_convergence_table(N_grid, J_grid, params, Sval, scheme_class):\n\n    est_prices = []\n    errex = []\n    errors = []\n    cpu_times = []\n\n    for N, J in zip(N_grid, J_grid):\n        params['N'] = N\n        params['J'] = J\n\n        start = time.time()\n        scheme = scheme_class(**params)\n        U, _ = scheme.solve()\n        tcpu = time.time() - start\n\n        price_est = scheme.interpolate(Sval, U)\n\n        est_prices.append(price_est)\n        cpu_times.append(tcpu)\n\n    est_prices = np.array(est_prices)\n    errors = np.zeros(len(est_prices))\n    errors[1:] = np.abs(np.diff(est_prices))\n    cpu_times = np.array(cpu_times)\n\n    # Ordre de convergence global\n    alpha = np.zeros(len(errors))\n    h_step = (params[\"Smax\"] - params[\"Smin\"]) / (J_grid + 1)\n    alpha[1:] = np.where(\n        (errors[:-1] > 0) & (errors[1:] > 0) & (h_step[:-1] > h_step[1:]),\n        np.log(errors[:-1] / errors[1:]) / np.log(h_step[:-1] / h_step[1:]),\n        0\n    )\n    df = pd.DataFrame({\n        \"J\": J_grid,\n        \"N\": N_grid,\n        \"U(s)\": est_prices,\n        \"error\": errors,\n        \"alpha\": alpha,\n        \"tcpu\": cpu_times\n    })\n\n    return df.round(6)\n```\n:::\n\n\n::: {#1517e2a2 .cell execution_count=14}\n``` {.python .cell-code}\nSval = 90\nJ_grid = np.array([20, 40, 80, 160, 320])\n\nN_grid = np.array([2*(j**2)/10 for j in J_grid]).astype(int)\n\nprint(\"Cas N = J\\n\", \"=\"*75)\n\nprint(\"Convergence Table for Scheme EE:\")\nprint(get_convergence_table(N_grid, J_grid-1, params, Sval, SchemeEE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCas N = J\n ===========================================================================\nConvergence Table for Scheme EE:\n     J      N       U(s)     error     alpha      tcpu\n0   19     80  12.947098  0.000000  0.000000  0.000573\n1   39    320  13.064717  0.117619  0.000000  0.001415\n2   79   1280  13.109572  0.044855  1.390781  0.005432\n3  159   5120  13.117805  0.008233  2.445784  0.019646\n4  319  20480  13.119987  0.002183  1.915301  0.082647\n```\n:::\n:::\n\n\nordre h^2 + dt  ==> division de l'erreur par 4.\n\n<!-- ### Condition de stabilit√© (CFL) et convergence -->\n\n<!-- L‚Äô√©tude de la condition de CFL met en √©vidence le caract√®re conditionnellement stable du sch√©ma d‚ÄôEuler explicite. Comme observ√© sur les figures, lorsque le maillage spatial est raffin√© sans diminution suffisante du pas de temps, la condition de stabilit√© est viol√©e et la solution num√©rique pr√©sente des oscillations marqu√©es. √Ä l‚Äôinverse, lorsque\nN et J sont augment√©s conjointement, la condition de CFL est mieux respect√©e et le comportement du sch√©ma s‚Äôam√©liore.\n\nOn remarque par ailleurs que les valeurs calcul√©es de la CFL sont identiques pour le payoff standard et pour le payoff tronqu√©. Ce r√©sultat est attendu, puisque la condition de stabilit√© d√©pend uniquement des param√®tres num√©riques et du mod√®le, en particulier du pas de temps\nŒît, du pas d‚Äôespace h, de la volatilit√©\nœÉ et de la borne sup√©rieure\nSmax et non de la r√©gularit√© du payoff. -->\n\n\nPour compl√©ter l‚Äôanalyse de la stabilit√©, il est √©galement int√©ressant d‚Äô√©tudier la convergence du sch√©ma.\nPour √©tudier l'ordre de convergence du sch√©ma, nous avons utilis√© une grille pour J qui varie en doublant √† chaque fois, et une grille pour N qui varie selon la r√®gle $2 \\times \\frac{J^2}{10}$.\nEtant donn√© le fait que l'ordre th√©orique de convergence du sch√©ma d'Euler explicite pour l'√©quation de Black-Scholes est de 2 en espace et de 1 en temps, on s'attend √† ce que l'erreur diminue d'un facteur de 4 √† chaque √©volution de la grille.\nLa table de convergence pr√©sent√©e ci-dessous montre l‚Äô√©volution de la solution num√©rique U(s) lorsque le nombre de points spatiaux\nJ et le nombre de pas temporels N sont augment√©s.\n\nEn respectant la r√®gle de variation des grilles pour J et N, on s'assure que les deux contributions √† l'erreur, i.e. l'erreur spatiale et l'erreur temporelle, diminuent de mani√®re coh√©rente, ce qui permet d'observer une convergence plus r√©guli√®re du sch√©ma et donc un ordre de convergence plus clair.\n\nOn observe que l‚Äôerreur diminue progressivement au fur et √† mesure que le maillage spatial et temporel est raffin√©, tandis que le facteur\nŒ± (estimant l‚Äôordre de convergence en espace) tend vers la valeur th√©orique attendue (2), ce qui confirme que le sch√©ma d‚ÄôEuler explicite converge correctement sous la condition de CFL.\n\nLa colonne tcpu montre que ce raffinement s‚Äôaccompagne d‚Äôun co√ªt computationnel croissant, le temps de calcul augmentant rapidement lorsque le maillage spatial et temporel est affin√©.\n\n## Schemas implicites\n\n\nApr√®s avoir √©tudi√© le sch√©ma d‚ÄôEuler explicite, nous nous int√©ressons √† des sch√©mas implicites et semi-implicites (Euler implicite, Crank-Nicolson...). Ce passage est principalement motiv√© par le fait que le sch√©ma explicite est conditionnellement stable et impose une limitation relativement stricte sur le pas de temps Œît et le maillage via la condition CFL. Les sch√©mas implicites, eux, offrent une stabilit√© plus grande, permettant d‚Äôutiliser des pas de temps plus importants.\n\nDans le cas du sch√©ma d‚ÄôEuler implicite (et plus g√©n√©ralement pour tout sch√©ma implicite appliqu√© aux options am√©ricaines), on est conduit √† r√©soudre √† chaque pas de temps un syst√®me non lin√©aire discret, correspondant √† un probl√®me d‚Äôobstacle v‚â•œï. Pour traiter ce syst√®me, nous utilisons diverses m√©thodes num√©riques, telles que la m√©thode PSOR (Projected Successive Over-Relaxation) ou une m√©thode de type Newton semi-smooth.\n\nCes sch√©mas compl√©mentaires nous permettent donc de comparer pr√©cision, stabilit√© et co√ªt computationnel, tout en g√©rant correctement la contrainte inh√©rente aux options am√©ricaines.\n\n### Splitting Euler Implicit scheme & Splitting Crank-Nicolson Scheme\n\nPour √©tudier le comportement du sch√©ma splitting d'Euler implicite, nous nous sommes directement plac√©s dans le cas o√π N=20 et J=50, qui avait montr√© des oscillations dans le sch√©ma explicite. Les r√©sultats obtenus sont pr√©sent√©s dans le graphique ci-dessous. Comme on peut le constater, le sch√©ma d'Euler implicite produit une approximation stable et sans oscillations du prix du put europ√©en, m√™me pour des valeurs √©lev√©es de N et J. Cela confirme la stabilit√© inconditionnelle du sch√©ma implicite, qui ne d√©pend pas de la relation entre le pas de temps et le pas d'espace.\n\n::: {#ccd4d4f9 .cell execution_count=15}\n``` {.python .cell-code}\nparams['J'] = 20\nparams['N'] = 50\n\nprint(\"Param√®tres financiers:\")\nprint(\"r=%.2f\" %r_, \"sigma=%.2f\" %sigma_, \"K=%.0f\" %K_, \"T=%.0f\" %T_)\n\nprint(\"Param√®tres num√©riques:\")\nprint(\"J=%.0f\" %params['J'], \"N=%.0f\" %params['N'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParam√®tres financiers:\nr=0.10 sigma=0.30 K=100 T=1\nParam√®tres num√©riques:\nJ=20 N=50\n```\n:::\n:::\n\n\n::: {#f68ee015 .cell execution_count=16}\n``` {.python .cell-code}\nei_split = SplittingScheme(**params)\nU,t = ei_split.solve()\ns = ei_split.s\ndt = ei_split.dt\n\nplt.plot(s,U,label=\"t=%.2f\" %(t+dt))\nplt.plot(s,ei_split.phi(s), 'k--', label=\"payoff\")\nplt.xlabel(\"s\")\nplt.ylabel(\"u(t,s)\")\nplt.title(\"Evolution du prix du put au cours du temps [Splitting Euler Implicite]\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](edp_american_opt_files/figure-html/cell-17-output-1.png){}\n:::\n:::\n\n\nLe sch√©ma de splitting d'Euler implicite est un sch√©ma implicite qui permet de s√©parer la partie lin√©aire de l'EDP de la partie non lin√©aire. En appliquant ce sch√©ma, on observe, ci dessus, une √©volution du prix du put au cours du temps qui est plus stable que celle obtenue avec le sch√©ma d'Euler explicite.\n\nBien qu'ils puissent √™tre moins pr√©cis qu'un vrai sch√©ma d'Euler implicite \"fully implicit\", les sch√©mas de splitting d'Euler implicite et de splitting de Crank-Nicolson sont plus simples √† impl√©menter et peuvent offrir une bonne approximation du prix du put am√©ricain, tout en √©tant plus stables que le sch√©ma d'Euler explicite. Par ailleurs, en ce qui concerne les ordres de convergence, les sch√©mas de splitting d'Euler implicite et de splitting de Crank-Nicolson peuvent pr√©senter des ordres de convergence similaires √† ceux des sch√©mas d'Euler implicite et de Crank-Nicolson classiques.\n\n::: {#55101c6a .cell execution_count=17}\n``` {.python .cell-code}\nN_grid = J_grid = np.array([20*(2**k) for k in range(5)]).astype(int)\n\nprint(\"Splitting scheme\")\nprint(\"=\"*75, \"\\nConvergence Table for Scheme EI:\")\nprint(get_convergence_table(N_grid, J_grid-1, params, Sval, SplittingScheme))\n\nprint(\"=\"*75, \"\\nConvergence Table for Scheme CN:\")\nprint(get_convergence_table(N_grid, J_grid-1, params, Sval, SchemeCN))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSplitting scheme\n=========================================================================== \nConvergence Table for Scheme EI:\n     J    N       U(s)     error     alpha      tcpu\n0   19   20  12.771151  0.000000  0.000000  0.001442\n1   39   40  12.958929  0.187778  0.000000  0.001753\n2   79   80  13.054834  0.095904  0.969364  0.004257\n3  159  160  13.089790  0.034957  1.456030  0.010195\n4  319  320  13.105599  0.015809  1.144811  0.026634\n=========================================================================== \nConvergence Table for Scheme CN:\n     J    N       U(s)     error     alpha      tcpu\n0   19   20  12.888852  0.000000  0.000000  0.000767\n1   39   40  13.021900  0.133049  0.000000  0.001050\n2   79   80  13.090984  0.069084  0.945528  0.002674\n3  159  160  13.107807  0.016823  2.037952  0.006654\n4  319  320  13.114979  0.007172  1.229912  0.019724\n```\n:::\n:::\n\n\n### PSOR Algorithm\n\nComme attendu, le sch√©ma PSOR prend plus de temps √† converger que les sch√©mas d'Euler implicite et de Crank-Nicolson, en raison de la nature it√©rative de la m√©thode PSOR. Cependant, il offre une bonne approximation du prix du put am√©ricain, tout en √©tant plus stable que le sch√©ma d'Euler explicite.\n\n::: {#c4f81aaf .cell execution_count=18}\n``` {.python .cell-code}\nparams['J'] = 100 -1\nparams['N'] = 10\n\n\nprint(\"Param√®tres financiers:\")\nprint(\"r=%.2f\" %r_, \"sigma=%.2f\" %sigma_, \"K=%.0f\" %K_, \"T=%.0f\" %T_)\n\nprint(\"Param√®tres num√©riques:\")\nprint(\"J=%.0f\" %params['J'], \"N=%.0f\" %params['N'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParam√®tres financiers:\nr=0.10 sigma=0.30 K=100 T=1\nParam√®tres num√©riques:\nJ=99 N=10\n```\n:::\n:::\n\n\n::: {#e9b9967b .cell execution_count=19}\n``` {.python .cell-code}\npsor = PSOR(**params, payoff=1)\nU,t = psor.solve() # omega = 1.5 pour une convergence rapide\ns = psor.s\ndt = psor.dt\n\nplt.figure(figsize=(6, 5))\nplt.plot(s,U,label=\"t=%.2f\" %(t))\nplt.plot(s,psor.phi(s), 'k--', label=\"payoff\")\nplt.xlabel(\"s\")\nplt.ylabel(\"u(t,s)\")\nplt.title(\"Evolution du prix du put europ√©en au cours du temps [PSOR]\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](edp_american_opt_files/figure-html/cell-20-output-1.png){}\n:::\n:::\n\n\nCependant, elle peut √™tre acc√©l√©r√©e en choisissant un param√®tre de relaxation $\\omega$ appropri√©, ce qui peut r√©duire le nombre d'it√©rations n√©cessaires pour atteindre la convergence. Nous constatons que pour des valeurs de $\\omega$ proches de 1.5, la m√©thode PSOR converge plus rapidement que pour des valeurs plus proches de 1, ce qui sugg√®re que l'over-relaxation peut √™tre b√©n√©fique pour acc√©l√©rer la convergence de la m√©thode PSOR.\n\n::: {#6cf089cd .cell execution_count=20}\n``` {.python .cell-code}\n# comparing time\n\nomegas = [1.2, 1.5, 1.8, 1.9]\n\nfor omega in omegas:\n    psor = PSOR(**params, payoff=1)\n    start_time = time.time()\n    U, t = psor.solve(omega=omega)\n    end_time = time.time()\n    print(f\"Omega: {omega}, Time taken: {end_time - start_time:.4f} seconds\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOmega: 1.2, Time taken: 50.6897 seconds\nOmega: 1.5, Time taken: 44.9621 seconds\nOmega: 1.8, Time taken: 27.1073 seconds\nOmega: 1.9, Time taken: 50.4578 seconds\n```\n:::\n:::\n\n\n### Semi-smooth Newton's method\n\nEn g√©n√©ral, la m√©thode PSOR est une m√©thode efficace pour r√©soudre les probl√®mes d'obstacle associ√©s aux options am√©ricaines, mais elle peut √™tre moins rapide que les m√©thodes de type Newton pour des probl√®mes de grande taille ou pour des sch√©mas d'ordre sup√©rieur.\n\nPour ce faire, nous avons impl√©ment√© une m√©thode de type Newton pour r√©soudre le probl√®me d'obstacle √† chaque pas de temps. Cette m√©thode consiste √† lin√©ariser le probl√®me d'obstacle autour d'une solution approximative √† chaque it√©ration, et √† r√©soudre le probl√®me lin√©aris√© pour obtenir une nouvelle approximation.\n\n::: {#55c766e2 .cell execution_count=21}\n``` {.python .cell-code}\nparams['J'] = 100 -1\nparams['N'] = 10\n\n\nprint(\"Param√®tres financiers:\")\nprint(\"r=%.2f\" %r_, \"sigma=%.2f\" %sigma_, \"K=%.0f\" %K_, \"T=%.0f\" %T_)\n\nprint(\"Param√®tres num√©riques:\")\nprint(\"J=%.0f\" %params['J'], \"N=%.0f\" %params['N'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParam√®tres financiers:\nr=0.10 sigma=0.30 K=100 T=1\nParam√®tres num√©riques:\nJ=99 N=10\n```\n:::\n:::\n\n\n::: {#bfc9dbda .cell execution_count=22}\n``` {.python .cell-code}\nnewtonss = NewtonSemiSmooth(**params, payoff=1)\nU,t = newtonss.solve()\ns = newtonss.s\ndt = newtonss.dt\n\nplt.figure(figsize=(6, 5))\nplt.plot(s,U,label=\"t=%.2f\" %(t))\nplt.plot(s,newtonss.phi(s), 'k--', label=\"payoff\")\nplt.xlabel(\"s\")\nplt.ylabel(\"u(t,s)\")\nplt.title(\"Evolution du prix du put europ√©en au cours du temps [Newton Semi-Smooth]\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](edp_american_opt_files/figure-html/cell-23-output-1.png){}\n:::\n:::\n\n\n### Mini-conclusion sur les sch√©ma implicites\n\nL‚Äô√©tude des sch√©mas implicites et semi-implicites montre que, lorsque le maillage spatial J et le pas temporel N sont raffin√©s, toutes les m√©thodes test√©es produisent des solutions num√©riques de plus en plus pr√©cises. Les ordres de convergence estim√©s (Œ±) sont coh√©rents avec les pr√©dictions th√©oriques : proches de 1 pour Euler implicite et proches de 2 pour Crank-Nicolson.\n\nLe raffinement du maillage et du pas de temps s‚Äôaccompagne d‚Äôune augmentation notable du temps de calcul, ce que mettent en √©vidence les tables de convergence et qui illustre clairement le compromis entre pr√©cision et co√ªt computationnel.\n\nEn termes de qualit√© des solutions, les m√©thodes num√©riques explor√©es (PSOR et Newton semi-smooth) produisent des r√©sultats lisses et coh√©rents, respectant correctement la contrainte d‚Äôobstacle.\n\n## Higher order schemes\n\nApr√®s avoir √©tudi√© les sch√©mas implicites classiques et les m√©thodes de r√©solution pour le probl√®me d‚Äôobstacle, nous consid√©rons √©galement un sch√©ma d‚Äôordre 2, le BDF2, qui am√©liore la pr√©cision temporelle tout en prenant en compte l‚Äôobstacle.\n\n### BDF Scheme\n\nLe sch√©ma BDF2 est test√© avec les m√™mes param√®tres de maillage spatial et de pas de temps que les sch√©mas pr√©c√©dents. Le graphique ci-dessous montre que le prix du put europ√©en reste lisse et coh√©rent, respectant correctement la contrainte d‚Äôobstacle, de mani√®re similaire aux autres m√©thodes implicites √©tudi√©es.\n\n::: {#89b22ccc .cell execution_count=23}\n``` {.python .cell-code}\nparams['J'] = 100 -1\nparams['N'] = 10\n\nbdf2 = BdfScheme(**params, payoff=1)\nU,t = bdf2.solve()\ns = bdf2.s\ndt = bdf2.dt\n\nplt.figure(figsize=(6, 5))\nplt.plot(s,U,label=\"t=%.2f\" %(t))\nplt.plot(s,bdf2.phi(s), 'k--', label=\"payoff\")\nplt.xlabel(\"s\")\nplt.ylabel(\"u(t,s)\")\nplt.title(\"Evolution du prix du put europ√©en au cours du temps [BDF2]\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](edp_american_opt_files/figure-html/cell-24-output-1.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "edp_american_opt_files"
    ],
    "filters": [],
    "includes": {}
  }
}