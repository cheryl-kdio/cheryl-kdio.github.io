---
title: "Finite difference Methods for American Options"
subtitle: "EDP in finance"
author:
  - name: Cheryl KOUADIO
  - name: Marilene Kougoum
categories: [paper,m2mo,edp]
date: "2026-02-08"
jupyter: python3
---


Dans ce TP, on √©tudie des sch√©mas num√©riques permettant d'approcher la solution de l'√©quation de Black-Scholes pour les options am√©ricaines. On considerera en particulier deux cas de payoff pour les options am√©ricaines :

- **payoff 1:** le cas de put standard de payoff $\phi_1(s) = (K-s)^+$, avec $K$ le prix d'exercice de l'option. Ce payoff est connu pour avoir de bonnes propri√©t√©s de r√©gularit√©, i.e. il est continu et m√™me lipschitzien, ce qui facilite l'analyse num√©rique.

- **payoff 2:** le cas d'un produit de payoff $\phi_2(s) = K \mathbf{1}_{\frac{K}{2} \leq s \leq K }$, qui correspond √† une option de type "cash-or-nothing" (payoff en cash) avec barri√®re. Ce payoff est plus irr√©gulier, puisqu'il est discontinu, ce qui rend l'analyse num√©rique plus d√©licate.

Dans les deux cas, l'EDP correspond √† un syst√®me non lin√©aire d'√©quations aux d√©riv√©es partielles suivant :
$$
\begin{cases}
\min \left( \frac{\partial v}{\partial t} - \frac{1}{2} \sigma^2 s^2 \frac{\partial^2 v}{\partial s^2} - r s \frac{\partial v}{\partial s} + r v, v - \phi \right) = 0, \quad (t,s) \in (0,T) \times (S_{min}, S_{max}), \\
v(t, S_{min}) = v_l(t), \quad t \in (0,T), \\
v(t, S_{max}) = v_r(t) := 0, \quad t \in (0,T), \\
v(0,s) = g(s), \quad s \in (S_{min}, S_{max}),
\end{cases}
$$

Dans le cas du payoff 1, on a $v_l(t) := \phi(S_{min}) = K - S_{min}$, tandis que dans le cas du payoff 2, on a $v_l(t) := \phi(S_{min}) = 0$.

Ces sch√©mas nous permettront d'obtenir une approximation num√©rique de la fonction de prix d'un put europ√©en $v(t,s)$, avec $t \in [0,T]$ et $s \in [S_{min}, S_{max}]$.

Les sch√©mas num√©riques permettant d'approcher cette EDP abord√©s ici sont :
1. le sch√©ma d'Euler explicite
2. le sch√©ma d'Euler implicite (et plus g√©n√©ralement pour tout sch√©ma implicite pour les options am√©ricaines), on est conduit √† un systeme non lin√©aire discret √† r√©soudre √† chaque pas de temps, qui √† la forme d'un "probl√®me d'obstacle".
2. On s'int√©ressera √† diverses m√©thodes num√©riques de r√©solution de ce syst√®me, telles que la m√©thode PSOR (projected successive over-relaxation), une m√©thode de type Newton.


# M√©thodes num√©riques

Nous consid√©rons la grille discr√®te suivante : $h = \frac{S_{max} - S_{min}}{J + 1}$ et $\Delta t = \frac{T}{N}$, avec $J$ et $N$ des entiers positifs, et :
- $s_j = S_{min} + j h$, pour $j = 0, \ldots, J + 1$,
- $t_n = n \Delta t$, pour $n = 0, \ldots, N$.

On cherche une approximation $U_j^n \approx v(t_n, s_j)$ pour $j = 1, \ldots, J$ et $n = 0, \ldots, N$.
Les sch√©mas aux diff√©rences finies nous permettront de discr√©tiser l'√©quation de Black-Scholes du prix d'un put am√©ricain sur cette grille.

## Explicit Euler Scheme or Euler Forward Scheme

Le sch√©ma d'Euler explicite est un sch√©ma bas√© sur une discr√©tisation explicite en temps. La discr√©tisation de l'EDP est bas√©e sur des approximations centr√©es. D√®s lors, on approxime les d√©riv√©es partielles de la mani√®re suivante :

$$
\begin{cases}
min(\frac{U_j^{n+1} - U_j^n}{\Delta t} - \frac{1}{2} \sigma^2 s_j^2 \frac{U_{j+1}^n - 2 U_j^n + U_{j-1}^n}{h^2} - r s_j \frac{U_{j+1}^n - U_{j-1}^n}{2 h} + r U_j^n, U^{n+1}_j - \phi(s_j))= 0, \quad j = 1, \ldots, J,\quad n = 0, \ldots, N-1. \\
U_0^n = v_l(t_n), \quad n = 0, \ldots, N-1. \\
U_{J+1}^n = v_r(t_n), \quad n = 0, \ldots, N-1.
\end{cases}
$$

On peut la r√©√©crire sous la forme matricielle afin d'extraire une solution num√©rique dite explicite :
Sous forma matricielle, le sch√©ma s'√©crit :

$$
\begin{cases}
min(\frac{U^{n+1} - U^n}{\Delta t} +  A U^n + q(t_n), U^{n+1} - g) = 0, \quad n = 0, \ldots, N-1, \\
U^0 = (\phi(s_i))_{1 \leq i \leq J},
\end{cases}
$$

o√π
- g est un vecteur de $\mathbb{R}^J$ d√©fini par $g_j = \phi(s_j)$ pour $j = 1, \ldots, J$,

-   $A$ est une matrice carr√©e tridiagonale de taille $J \times J$.
    En posant $\alpha_j = \frac{\sigma^2}{2} \frac{s_j^2}{h^2}$ et $\beta_j = r \frac{s_j}{2 h}$, les coefficients de la matrice $A$ sont donn√©s par :

    $$
    \begin{cases}
    A_{j,j-1} = -\alpha_j + \beta_j, \quad j= 2, \ldots, J, \\
    A_{j,j} = 2\alpha_j + r, \quad j = 1, \ldots, J, \\
    A_{j,j+1} = -\alpha_j - \beta_j, \quad j = 1, \ldots, J, \\
    \end{cases}
    $$

-   $q(t_n)$ un vecteur de $\mathbb{R}^J$ qui d√©pendent des param√®tres du mod√®le et de la discr√©tisation spatiale donn√© par :

    $$
    q_j(t_n) =
    \begin{cases}
    (-\alpha_1 + \beta_1) U_0^n, \quad j = 1, \\
    0, \quad j = 2, \ldots, J-1, \\
    (-\alpha_J + \beta_J) U_{J+1}^n, \quad j = J.
    \end{cases}
    $$

De fait, on obtient la relation de r√©currence explicite permettant de calculer $U^{n+1}$ en fonction de $U^n$ :

$$
U^{n+1} = max(U^n - \Delta t ( A U^n + q(t_n)), g)), \quad n = 0, \ldots, N-1,
$$

## Implicit Euler Scheme

Pour des raisons de stabilit√©, on peut √©galement utiliser un sch√©ma d'Euler implicite, qui est bas√© sur une discr√©tisation implicite en temps.

### Splitting scheme
Une premi√®re approche est de consid√©rer le "splitting scheme", qui consiste √† s√©parer la partie lin√©aire de l'EDP de la partie non lin√©aire :
(i) On calcule $U^{n+1,(1)}$ tel que $U^{n+1,(1)} - U^n + \Delta t (A U^{n+1,(1)} + q(t_{n+1})) = 0$,
(ii) On calcule $U^{n+1}$ tel que $U^{n+1} = max(U^{n+1,(1)}, g)$.

### M√©thodes num√©riques de r√©solution
Une seconde approche est de consid√©rer un sch√©ma d'Euler implicite "fully implicit", qui consiste √† discr√©tiser l'EDP de mani√®re implicite en temps, ce qui conduit √† un syst√®me non lin√©aire √† r√©soudre √† chaque pas de temps :
$$\begin{cases}
min(\frac{U^{n+1} - U^n}{\Delta t} +  A U^{n+1} + q(t_{n+1}), U^{n+1} - g) = 0, \quad n = 0, \ldots, N-1, \\
U^0 = (\phi(s_i))_{1 \leq i \leq J}.
\end{cases}$$

En posant $B = I + \Delta t A$ et $b = U^n - \Delta t q(t_{n+1})$, le probl√®me se transforme en la r√©solution d'un probl√®me d'obstacle √† chaque pas de temps ou il s'agit de trouver $x \in \mathbb{R}^J$ tel que $min(B x - b, x - g) = 0$. De fait, on a recours √† des m√©thodes num√©riques de r√©solution de ce type de probl√®me, telles que la m√©thode PSOR (projected successive over-relaxation) ou une m√©thode de type Newton.

#### PSOR Algorithm

La m√©thode PSOR est une m√©thode it√©rative de r√©solution de probl√®mes d'obstacle. Elle consiste √† it√©rer sur les composantes du vecteur $x$ en appliquant une relaxation projet√©e.

Tout d'abord, on d√©compose la matrice $B$ en une partie triangulaire inf√©rieure $L$, et une partie triangulaire strictement sup√©rieure $U$, de sorte que $B = L + U$. Ensuite, pour un temps fix√© $n$, on cherche √† trouver une solution $x$ du probl√®me d'obstacle en it√©rant sur les composantes du vecteur $x$ au temps fix√© en appliquant la formule suivante :
$$
x_j^{(k+1)} = max\left(g_j, \frac{\omega}{B_{j,j}} \left(b_j - \sum_{i=1}^{j-1} B_{j,i} x_i^{(k+1)} - \sum_{i=j+1}^{J} B_{j,i} x_i^{(k)} \right) + (1 - \omega) x_j^k \right) , \quad j = 1, \ldots, J,
$$


o√π $k$ est l'indice de l'it√©ration. La m√©thode converge vers la solution du probl√®me d'obstacle, et le taux de convergence d√©pend du choix du param√®tre de relaxation, i.e. du choix de la valeur de $\omega \in (0,2)$ dans la formule de relaxation.
Lorsque $\omega = 1$, la m√©thode PSOR correspond √† la m√©thode classique de Gauss-Seidel projet√©e. Lorsque $\omega \neq 1$, la m√©thode PSOR peut acc√©l√©rer la convergence, mais le choix optimal de $\omega$ d√©pend du probl√®me sp√©cifique et peut n√©cessiter une exp√©rimentation.

#### Semi-smooth Newton's method

La m√©thode de type Newton est une m√©thode it√©rative de r√©solution de probl√®mes non lin√©aires. Elle consiste √† lin√©ariser le probl√®me d'obstacle autour d'une solution approximative $x^{(k)}$ √† chaque it√©ration, et √† r√©soudre le probl√®me lin√©aris√© pour obtenir une nouvelle approximation $x^{(k+1)}$.

On cherche √† r√©soudre le probl√®me d'obstacle $F(x) = min(B x - b, x - g) = 0$ en it√©rant sur les approximations successives de la solution.
On lin√©arise le probl√®me d'obstacle autour de l'approximation $x^{(k)}$ en utilisant la formule de Taylor :
$$
F(x) \approx F(x^{(k)}) + F'(x^{(k)})(x - x^{(k)}),
$$

On cherche √† r√©soudre $F(x) = 0$. D√®s lors, √† chaque it√©ration, on r√©sout le probl√®me lin√©aris√© $F'(x^{(k)})(x - x^{(k)}) = -F(x^{(k)})$ pour obtenir une nouvelle approximation $x^{(k+1)}$. La m√©thode de type Newton converge quadratiquement vers la solution du probl√®me d'obstacle, ce qui en fait une m√©thode tr√®s efficace pour r√©soudre ce type de probl√®me.

$F'(x)$ est la matrice jacobienne de $F$ √† l'approximation $x$. La matrice jacobienne de $F$ est donn√©e par :
$$
F'(x)_{i,j} := \begin{cases}
B_{i,j}, \quad \text{si } B x - b < x - g, \\
\delta_{i,j}, \quad \text{sinon}.
\end{cases}
$$

## Higher order schemes

Enfin, nous envisagerons de comparer les sch√©mas d'Euler implicite, les sch√©mas de type Crank-Nicolson, et un sch√©ma d'ordre 2 tel que le BDF2.

# Impl√©mentations

Les diff√©rents sch√©mas num√©riques √©tudi√©s pour l‚Äô√©quation de Black‚ÄìScholes avec option am√©ricaine partagent une structure commune. Nous introduisons donc une classe de base abstraite SchemeBase qui regroupe les param√®tres financiers et num√©riques, la construction de la grille discr√®te, les conditions initiales et aux limites, ainsi que la discr√©tisation spatiale de l‚Äôop√©rateur de Black-Scholes √† travers la matrice
A et le vecteur
q(t).

Les sch√©mas sp√©cifiques h√©ritent de cette classe de base et impl√©mentent la m√©thode solve(). En particulier, nous d√©finissons les classes suivantes :
- `SchemeEE` pour le sch√©ma d'Euler explicite,
- `SplittingScheme` pour le sch√©ma splitting d'Euler implicite,
- `SchemeCN` pour le sch√©ma de Crank-Nicolson,
- `PSOR` pour la m√©thode PSOR,
- `NewtonSemiSmooth` pour la m√©thode de r√©solution newton semi smooth, et
- `BdfScheme` pour le schema de r√©solution BDF2.


```{python}
# Package imports

import numpy as np
import matplotlib.pyplot as plt
import numpy.linalg as lng
from scipy.sparse import diags,eye
from abc import ABC, abstractmethod
import scipy.stats as stats
from scipy.sparse import csr_matrix as sparse
from scipy.sparse.linalg import spsolve
import pandas as pd
import time
import warnings
import numpy.linalg as lng
from tqdm import tqdm

warnings.filterwarnings("ignore")
```

```{python}
class SchemeBase(ABC):
    """
    Classe de base pour les sch√©mas num√©riques de l'√©quation de Black-Scholes.
    """
    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):
        # Financial parameters
        self.r = r
        self.sigma = sigma
        self.K = K
        self.T = T

        # Numerical parameters
        self.N = N
        self.J = J
        self.Smin = Smin
        self.Smax = Smax
        self.payoff = payoff

        # Grids
        self.dt = T / N
        self.h = (Smax - Smin) / (J + 1)
        self.s = Smin + self.h * np.arange(1, J + 1)


        # Operator
        self.A, self.alpha, self.beta = self._build_matrix_A()

    def phi(self,s):
        """
        Condition initiale (payoff) pour un put am√©ricain.
        ùúô(s) = max(K - s, 0) si payoff=1
             = K si K * 0.5 <= s <= K sinon 0 si payoff=2
        """
        if self.payoff == 1:
            return np.maximum(self.K - s, 0)
        elif self.payoff  == 2:
            return np.where((self.K * 0.5 <= s) & (s <= self.K), self.K, 0)

    def uleft(self, t):
        """
        Condition aux limites √† gauche pour un put am√©ricain.
        u( t, Smin ) = K * exp(-r * t) - S
        """
        if self.payoff  == 1 :
            return self.K - self.Smin if self.Smin > 0 else None
        elif self.payoff  == 2 :
            return 0.0


    def uright(self, t):
        """
        Condition aux limites √† droite pour un put am√©ricain.
        u( t, Smax ) = 0
        """
        return 0.0

    def _build_matrix_A(self):
        """
        Matrice d'amplification A.
        """
        alpha = 0.5 * self.sigma**2 * (self.s**2 / self.h**2)
        beta  = self.r * self.s / (2 * self.h)

        lower = -alpha[1:] + beta[1:]        # sous-diagonale
        main  = 2 * alpha + self.r            # diagonale principale
        upper = -alpha[:-1] - beta[:-1]       # sur-diagonale

        A = diags(
            diagonals=[lower, main, upper],
            offsets=[-1, 0, 1],
            shape=(self.J, self.J),
            format="csr"
        )

        return A, alpha, beta


    def q(self, t):
        """
        Vecteur des conditions aux limites.
        """
        y = np.zeros(self.J)
        y[0]  = (-self.alpha[0] + self.beta[0]) * self.uleft(t)
        y[-1] = (-self.alpha[-1] - self.beta[-1]) * self.uright(t)
        return y

    def interpolate(self, Sval, U):
        """
        Interpolation lin√©aire pour obtenir la valeur approxim√©e d'un put
        en un point spot Sval donn√©.
        """
        if Sval <= self.Smin:
            return self.uleft(self.T)
        elif Sval >= self.Smax:
            return self.uright(self.T)
        else:
            return np.interp(Sval, self.s, U)

    # Abstract method
    @abstractmethod
    def solve(self):
        """
        M√©thode abstraite de r√©solution du sch√©ma num√©rique.
        """
        raise NotImplementedError("M√©thode solve() √† impl√©menter dans la classe fille")
```

```{python}
class SchemeEE(SchemeBase):
    """
    Sch√©ma d'Euler explicite.
    """
    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):
        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)
        self.scheme_name = "EE"

    def solve(self):
        """
        R√©solution du sch√©ma d'Euler explicite.
        """
        U = self.phi(self.s)
        g = self.phi(self.s)

        for n in range(self.N):
            t = n * self.dt
            U = np.maximum(U - self.dt * (self.A @ U + self.q(t)), g)

        return U,t
```

```{python}
class SplittingScheme(SchemeBase):
    """
    Sch√©ma d'Euler implicite "Splitting scheme".
    """
    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):
        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)
        self.scheme_name = "EI-AMER-SPLIT"

    def solve(self):
        U = self.phi(self.s)
        g = self.phi(self.s)
        I = eye(self.J, format="csr")

        for n in range(self.N):
            t = n * self.dt
            U = spsolve(I + self.dt * self.A, U - self.dt * self.q(t))
            U = np.maximum(U, g)

        return U,t
```

```{python}
class SchemeCN(SchemeBase):
    """
    Sch√©ma de Crank-Nicolson.
    """
    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):
        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)
        self.scheme_name = "CN-AMER-SPLIT"

    def solve(self):
        U = self.phi(self.s)
        g = self.phi(self.s)
        I = eye(self.J, format="csr")
        factor_minus = I - 0.5 * self.dt * self.A
        factor_plus = I + 0.5 * self.dt * self.A

        for n in range(self.N):
            t = n * self.dt
            U = spsolve(factor_plus, factor_minus@U - self.dt * self.q(t))
            U = np.maximum(U, g)
        return U,t
```

```{python}
class PSOR(SchemeBase):
    """
    Sch√©ma PSOR
    """

    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):
        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)
        self.scheme_name = "EI-AMER-PSOR"

    def solve(self, omega=1, tol=1e-6, max_iter_=100):

        g = self.phi(self.s).copy()
        I = eye(self.J, format="csr")
        B = I + self.dt * self.A
        U = g.copy()

        # Boucle en temps
        for n in range(self.N):

            t = n * self.dt

            # Second membre f = U^{n+1} + dt * q(t_n)
            b = U + self.dt * self.q(t)

            # Initialisation PSOR
            U_new = U.copy()

            # Boucle PSOR
            for k in range(max_iter_):

                U_old = U_new.copy()
                # Boucle spatiale
                for i in range(self.J):
                    s1 = 0.0
                    for j in range(i):
                        s1 += B[i, j] * U_new[j]

                    s2 = 0.0
                    for j in range(i + 1, self.J):
                        s2 += B[i, j] * U_old[j]

                    ci = (b[i] - s1 - s2) / B[i, i]
                    U_new[i] = max(
                        (1 - omega )* U_old[i] + omega * ci     ,
                        g[i]
                    )

                error1 = lng.norm(U_new - U_old)
                # error2 = lng.norm(np.minimum(B @ U_new - b, U_new - g))
                # Crit√®re de convergence PSOR
                if error1 < tol:
                    break
            # Passage au temps suivant
            U = U_new.copy()

        return U, self.T
```

```{python}
class NewtonSemiSmooth(SchemeBase):
    """
    Euler implicite + Newton semi-smooth
    pour option am√©ricaine (probl√®me d'obstacle)
    """

    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):
        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)
        self.scheme_name = "EI-AMER-NEWTON-SS"

    def solve(self, tol=1e-8, max_iter_=20):

        # Obstacle (payoff)
        g = self.phi(self.s).copy()

        # Matrice implicite
        I = eye(self.J, format="csr")
        B = I + self.dt * self.A

        # Condition terminale
        U = g.copy()

        for n in range(self.N):

            t = n * self.dt
            b = U + self.dt * self.q(t)
            x = U.copy()

            # Boucle Newton semi-smooth
            for k in range(max_iter_):

                # F(x)
                Bx_b = B @ x - b
                x_g  = x - g
                F = np.minimum(Bx_b, x_g)

                # Test d'arr√™t
                if lng.norm(F, np.inf) < tol:
                    break

                # Construction de F'(x) (jacobienne g√©n√©ralis√©e)
                rows, cols, data = [], [], []

                for i in range(self.J):
                    if Bx_b[i] <= x_g[i]:
                        # ligne i de B
                        row = B.getrow(i)
                        rows.extend([i] * len(row.indices))
                        cols.extend(row.indices)
                        data.extend(row.data)
                    else:
                        # ligne i de I
                        rows.append(i)
                        cols.append(i)
                        data.append(1.0)

                DF = sparse((data, (rows, cols)), shape=(self.J, self.J))

                # √âtape de Newton : DF * delta = F
                delta = spsolve(DF, F)

                # Mise √† jour
                x = x - delta

            # Passage au temps suivant
            U = x.copy()

        return U, self.T
```

```{python}
class BdfScheme(SchemeBase):
    """
    Sch√©ma BDF2
    """

    def __init__(self, r, sigma, K, T, N, J, Smin, Smax, payoff=1):
        super().__init__(r, sigma, K, T, N, J, Smin, Smax, payoff)
        self.scheme_name = "BDF2-Obstacle-Newton"

    def solve(self):

        # Obstacle
        g = self.phi(self.s).copy()
        I = eye(self.J, format="csr")

        # ---------- Initialisation ----------
        # U^0
        U_nm1 = g.copy()

        # U^1 via Euler implicite (avec obstacle)
        B_euler = I + self.dt * self.A
        b_euler = U_nm1 + self.dt * self.q(self.dt)
        U_n = spsolve(B_euler, b_euler)
        U_n = np.maximum(U_n, g)   # projection autoris√©e uniquement ici (Euler)

        # ---------- Boucle BDF2 ----------
        for n in range(1, self.N):

            t = (n + 1) * self.dt
            factor1 = (3.0 / (2.0 * self.dt)) * I + self.A
            factor2 = (4.0 * U_n - U_nm1) / (2.0 * self.dt) - self.q(t)

            U = spsolve(factor1, factor2)
            U = np.maximum(U, g)

            U_nm1 = U_n.copy()
            U_n = U.copy()

        return U, self.T
```

# R√©sultats des sch√©mas num√©riques

## Euler Explicit Scheme


Nous √©tudions ici le comportement du sch√©ma d‚ÄôEuler explicite appliqu√© √† l‚Äô√©quation de Black‚ÄìScholes pour une option am√©ricaine de type put. Les simulations sont r√©alis√©es en faisant varier les param√®tres de discr√©tisation spatiale
J et temporelle
N, tout en imposant la contrainte d‚Äôobstacle √† chaque pas de temps.

Les figures pr√©sent√©es correspondent aux cas suivants (pour les deux payoffs consid√©r√©s) :

- N = 20, J = 50
- N = 20, J = 20
- N = 50, J = 20


Pour chaque configuration, le prix num√©rique de l‚Äôoption est compar√© au payoff, et la valeur associ√©e √† la condition de CFL est calcul√©e.

```{python}
r_ = 0.1
sigma_ = 0.3
K_ = 100
T_ = 1
Smin_ = 50
Smax_ = 250
print("Param√®tres financiers:")
print("r=%.2f" %r_, "sigma=%.2f" %sigma_, "K=%.0f" %K_, "T=%.0f" %T_)

# Definition des param√®tres dans un dictionnaire
params = dict(
    r=r_,
    sigma=sigma_,
    K=K_,
    T=T_,
    N=None, # Valeur √† d√©finir plus tard
    J=None, # Valeur √† d√©finir plus tard
    Smin=Smin_,
    Smax=Smax_
)
```

```{python}
J_values = [50, 20, 20]
N_values = [20, 20, 50]

cfl_records1 = []

fig, axes = plt.subplots(1, 3, figsize=(24, 8), sharey=False)
for j, (N_, J_) in enumerate(zip(N_values, J_values)):
    params['N'] = N_
    params['J'] = J_

    ee = SchemeEE(**params, payoff=1)
    U, t = ee.solve()
    s = ee.s
    dt = ee.dt

    #CFL condition
    CFL = dt / (ee.h ** 2) * (ee.sigma ** 2) * (ee.Smax ** 2)

    # Enregistrement dans la table
    cfl_records1.append({
        "N": N_,
        "J": J_,
        "CFL": CFL
    })

    ax = axes[j]
    ax.plot(s, U, label="Prix option")
    ax.plot(s, ee.phi(s), 'k--', label="Payoff")

    ax.set_title(f"N = {N_}, J = {J_}")
    ax.set_xlabel("s")
    if j == 0:
        ax.set_ylabel("u(t,s)")
    ax.legend()

plt.suptitle(
    f"Evolution du prix du put am√©ricain -- Scheme {ee.scheme_name}",
    fontsize=16
)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()
```

```{python}
J_values = [50, 20, 20]
N_values = [20, 20, 50]

cfl_records2 = []

fig, axes = plt.subplots(1, 3, figsize=(24, 8), sharey=False)
for j, (N_, J_) in enumerate(zip(N_values, J_values)):
    params['N'] = N_
    params['J'] = J_

    ee = SchemeEE(**params, payoff=2)
    U, t = ee.solve()
    s = ee.s
    dt = ee.dt

    #CFL condition
    CFL = dt / (ee.h ** 2) * (ee.sigma ** 2) * (ee.Smax ** 2)

    # Enregistrement dans la table
    cfl_records2.append({
        "N": N_,
        "J": J_,
        "CFL": CFL
    })

    ax = axes[j]
    ax.plot(s, U, label="Prix option")
    ax.plot(s, ee.phi(s), 'k--', label="Payoff")

    ax.set_title(f"N = {N_}, J = {J_}")
    ax.set_xlabel("s")
    if j == 0:
        ax.set_ylabel("u(t,s)")
    ax.legend()

plt.suptitle(
    f"Evolution du prix du put am√©ricain -- Scheme {ee.scheme_name}, N fix√© √† {N_}",
    fontsize=16
)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()
```

Les figures ci - dessus repr√©sentent le prix num√©rique de l‚Äôoption au temps final, compar√© au payoff, pour diff√©rentes configurations de maillage.

Les r√©sultats montrent que le comportement du sch√©ma d√©pend fortement du choix de
N et
J. Lorsque le maillage spatial est fin (
J=50) et que le nombre de pas de temps est relativement faible (
N=20), la solution num√©rique devient instable et pr√©sente de fortes oscillations, avec des valeurs non physiques. Ce ph√©nom√®ne traduit une instabilit√© du sch√©ma explicite.
En revanche, pour un maillage spatial plus grossier (
J=20) et un pas de temps suffisamment petit (
N=20 ou N=50), la solution obtenue est plus r√©guli√®re et respecte correctement la contrainte d‚Äôoption am√©ricaine, la solution restant au-dessus du payoff.

Ces observations sugg√®rent que la stabilit√© du sch√©ma d‚ÄôEuler explicite est √©troitement li√©e √† la relation entre le pas de temps et le pas d‚Äôespace, ce qui motive l‚Äôanalyse de la condition de stabilit√© de type CFL.


```{python}
cfl_df1 = pd.DataFrame(cfl_records1)  # Cas 1 : N fix√©
cfl_df2 = pd.DataFrame(cfl_records2)  # Cas 2 : N = J

cfl_df1 = cfl_df1.rename(columns={"CFL": "CFL (N=10)"})
cfl_df2 = cfl_df2.rename(columns={"CFL": "CFL (N=J)"})

print("Payoff standard:")
print("="*20)
print(cfl_df1)
print("Payoff tronqu√©:")
print("="*20)
print(cfl_df2)
```

L‚Äô√©tude de la condition de CFL met en √©vidence le caract√®re conditionnellement stable du sch√©ma d‚ÄôEuler explicite. Comme observ√© sur les figures, lorsque le maillage spatial est raffin√© sans diminution suffisante du pas de temps, la condition de stabilit√© est viol√©e et la solution num√©rique pr√©sente des oscillations marqu√©es. √Ä l‚Äôinverse, lorsque
N et J sont augment√©s conjointement, la condition de CFL est mieux respect√©e et le comportement du sch√©ma s‚Äôam√©liore.

On remarque par ailleurs que les valeurs calcul√©es de la CFL sont identiques pour le payoff standard et pour le payoff tronqu√©. Ce r√©sultat est attendu, puisque la condition de stabilit√© d√©pend uniquement des param√®tres num√©riques et du mod√®le, en particulier du pas de temps
Œît, du pas d‚Äôespace h, de la volatilit√©
œÉ et de la borne sup√©rieure
Smax et non de la r√©gularit√© du payoff.

```{python}
def get_convergence_table(N_grid, J_grid, params, Sval, scheme_class):

    est_prices = []
    errex = []
    errors = []
    cpu_times = []

    for N, J in zip(N_grid, J_grid):
        params['N'] = N
        params['J'] = J

        start = time.time()
        scheme = scheme_class(**params)
        U, _ = scheme.solve()
        tcpu = time.time() - start

        price_est = scheme.interpolate(Sval, U)

        est_prices.append(price_est)
        cpu_times.append(tcpu)

    est_prices = np.array(est_prices)
    errors = np.zeros(len(est_prices))
    errors[1:] = np.abs(np.diff(est_prices))
    cpu_times = np.array(cpu_times)

    # Ordre de convergence global
    alpha = np.zeros(len(errors))
    h_step = (params["Smax"] - params["Smin"]) / (J_grid + 1)
    alpha[1:] = np.where(
        (errors[:-1] > 0) & (errors[1:] > 0) & (h_step[:-1] > h_step[1:]),
        np.log(errors[:-1] / errors[1:]) / np.log(h_step[:-1] / h_step[1:]),
        0
    )
    df = pd.DataFrame({
        "J": J_grid,
        "N": N_grid,
        "U(s)": est_prices,
        "error": errors,
        "alpha": alpha,
        "tcpu": cpu_times
    })

    return df.round(6)
```

```{python}
Sval = 90
J_grid = np.array([20, 40, 80, 160, 320])

N_grid = np.array([2*(j**2)/10 for j in J_grid]).astype(int)

print("Cas N = J\n", "="*75)

print("Convergence Table for Scheme EE:")
print(get_convergence_table(N_grid, J_grid-1, params, Sval, SchemeEE))
```

ordre h^2 + dt  ==> division de l'erreur par 4.

<!-- ### Condition de stabilit√© (CFL) et convergence -->

<!-- L‚Äô√©tude de la condition de CFL met en √©vidence le caract√®re conditionnellement stable du sch√©ma d‚ÄôEuler explicite. Comme observ√© sur les figures, lorsque le maillage spatial est raffin√© sans diminution suffisante du pas de temps, la condition de stabilit√© est viol√©e et la solution num√©rique pr√©sente des oscillations marqu√©es. √Ä l‚Äôinverse, lorsque
N et J sont augment√©s conjointement, la condition de CFL est mieux respect√©e et le comportement du sch√©ma s‚Äôam√©liore.

On remarque par ailleurs que les valeurs calcul√©es de la CFL sont identiques pour le payoff standard et pour le payoff tronqu√©. Ce r√©sultat est attendu, puisque la condition de stabilit√© d√©pend uniquement des param√®tres num√©riques et du mod√®le, en particulier du pas de temps
Œît, du pas d‚Äôespace h, de la volatilit√©
œÉ et de la borne sup√©rieure
Smax et non de la r√©gularit√© du payoff. -->


Pour compl√©ter l‚Äôanalyse de la stabilit√©, il est √©galement int√©ressant d‚Äô√©tudier la convergence du sch√©ma.
Pour √©tudier l'ordre de convergence du sch√©ma, nous avons utilis√© une grille pour J qui varie en doublant √† chaque fois, et une grille pour N qui varie selon la r√®gle $2 \times \frac{J^2}{10}$.
Etant donn√© le fait que l'ordre th√©orique de convergence du sch√©ma d'Euler explicite pour l'√©quation de Black-Scholes est de 2 en espace et de 1 en temps, on s'attend √† ce que l'erreur diminue d'un facteur de 4 √† chaque √©volution de la grille.
La table de convergence pr√©sent√©e ci-dessous montre l‚Äô√©volution de la solution num√©rique U(s) lorsque le nombre de points spatiaux
J et le nombre de pas temporels N sont augment√©s.

En respectant la r√®gle de variation des grilles pour J et N, on s'assure que les deux contributions √† l'erreur, i.e. l'erreur spatiale et l'erreur temporelle, diminuent de mani√®re coh√©rente, ce qui permet d'observer une convergence plus r√©guli√®re du sch√©ma et donc un ordre de convergence plus clair.

On observe que l‚Äôerreur diminue progressivement au fur et √† mesure que le maillage spatial et temporel est raffin√©, tandis que le facteur
Œ± (estimant l‚Äôordre de convergence en espace) tend vers la valeur th√©orique attendue (2), ce qui confirme que le sch√©ma d‚ÄôEuler explicite converge correctement sous la condition de CFL.

La colonne tcpu montre que ce raffinement s‚Äôaccompagne d‚Äôun co√ªt computationnel croissant, le temps de calcul augmentant rapidement lorsque le maillage spatial et temporel est affin√©.

## Schemas implicites


Apr√®s avoir √©tudi√© le sch√©ma d‚ÄôEuler explicite, nous nous int√©ressons √† des sch√©mas implicites et semi-implicites (Euler implicite, Crank-Nicolson...). Ce passage est principalement motiv√© par le fait que le sch√©ma explicite est conditionnellement stable et impose une limitation relativement stricte sur le pas de temps Œît et le maillage via la condition CFL. Les sch√©mas implicites, eux, offrent une stabilit√© plus grande, permettant d‚Äôutiliser des pas de temps plus importants.

Dans le cas du sch√©ma d‚ÄôEuler implicite (et plus g√©n√©ralement pour tout sch√©ma implicite appliqu√© aux options am√©ricaines), on est conduit √† r√©soudre √† chaque pas de temps un syst√®me non lin√©aire discret, correspondant √† un probl√®me d‚Äôobstacle v‚â•œï. Pour traiter ce syst√®me, nous utilisons diverses m√©thodes num√©riques, telles que la m√©thode PSOR (Projected Successive Over-Relaxation) ou une m√©thode de type Newton semi-smooth.

Ces sch√©mas compl√©mentaires nous permettent donc de comparer pr√©cision, stabilit√© et co√ªt computationnel, tout en g√©rant correctement la contrainte inh√©rente aux options am√©ricaines.

### Splitting Euler Implicit scheme & Splitting Crank-Nicolson Scheme

Pour √©tudier le comportement du sch√©ma splitting d'Euler implicite, nous nous sommes directement plac√©s dans le cas o√π N=20 et J=50, qui avait montr√© des oscillations dans le sch√©ma explicite. Les r√©sultats obtenus sont pr√©sent√©s dans le graphique ci-dessous. Comme on peut le constater, le sch√©ma d'Euler implicite produit une approximation stable et sans oscillations du prix du put europ√©en, m√™me pour des valeurs √©lev√©es de N et J. Cela confirme la stabilit√© inconditionnelle du sch√©ma implicite, qui ne d√©pend pas de la relation entre le pas de temps et le pas d'espace.

```{python}
params['J'] = 20
params['N'] = 50

print("Param√®tres financiers:")
print("r=%.2f" %r_, "sigma=%.2f" %sigma_, "K=%.0f" %K_, "T=%.0f" %T_)

print("Param√®tres num√©riques:")
print("J=%.0f" %params['J'], "N=%.0f" %params['N'])
```

```{python}
ei_split = SplittingScheme(**params)
U,t = ei_split.solve()
s = ei_split.s
dt = ei_split.dt

plt.plot(s,U,label="t=%.2f" %(t+dt))
plt.plot(s,ei_split.phi(s), 'k--', label="payoff")
plt.xlabel("s")
plt.ylabel("u(t,s)")
plt.title("Evolution du prix du put au cours du temps [Splitting Euler Implicite]")
plt.legend()
plt.show()
```


Le sch√©ma de splitting d'Euler implicite est un sch√©ma implicite qui permet de s√©parer la partie lin√©aire de l'EDP de la partie non lin√©aire. En appliquant ce sch√©ma, on observe, ci dessus, une √©volution du prix du put au cours du temps qui est plus stable que celle obtenue avec le sch√©ma d'Euler explicite.

Bien qu'ils puissent √™tre moins pr√©cis qu'un vrai sch√©ma d'Euler implicite "fully implicit", les sch√©mas de splitting d'Euler implicite et de splitting de Crank-Nicolson sont plus simples √† impl√©menter et peuvent offrir une bonne approximation du prix du put am√©ricain, tout en √©tant plus stables que le sch√©ma d'Euler explicite. Par ailleurs, en ce qui concerne les ordres de convergence, les sch√©mas de splitting d'Euler implicite et de splitting de Crank-Nicolson peuvent pr√©senter des ordres de convergence similaires √† ceux des sch√©mas d'Euler implicite et de Crank-Nicolson classiques.

```{python}
N_grid = J_grid = np.array([20*(2**k) for k in range(5)]).astype(int)

print("Splitting scheme")
print("="*75, "\nConvergence Table for Scheme EI:")
print(get_convergence_table(N_grid, J_grid-1, params, Sval, SplittingScheme))

print("="*75, "\nConvergence Table for Scheme CN:")
print(get_convergence_table(N_grid, J_grid-1, params, Sval, SchemeCN))
```

### PSOR Algorithm

Comme attendu, le sch√©ma PSOR prend plus de temps √† converger que les sch√©mas d'Euler implicite et de Crank-Nicolson, en raison de la nature it√©rative de la m√©thode PSOR. Cependant, il offre une bonne approximation du prix du put am√©ricain, tout en √©tant plus stable que le sch√©ma d'Euler explicite.

```{python}
params['J'] = 100 -1
params['N'] = 10


print("Param√®tres financiers:")
print("r=%.2f" %r_, "sigma=%.2f" %sigma_, "K=%.0f" %K_, "T=%.0f" %T_)

print("Param√®tres num√©riques:")
print("J=%.0f" %params['J'], "N=%.0f" %params['N'])
```

```{python}
psor = PSOR(**params, payoff=1)
U,t = psor.solve() # omega = 1.5 pour une convergence rapide
s = psor.s
dt = psor.dt

plt.figure(figsize=(6, 5))
plt.plot(s,U,label="t=%.2f" %(t))
plt.plot(s,psor.phi(s), 'k--', label="payoff")
plt.xlabel("s")
plt.ylabel("u(t,s)")
plt.title("Evolution du prix du put europ√©en au cours du temps [PSOR]")
plt.legend()
plt.show()
```

Cependant, elle peut √™tre acc√©l√©r√©e en choisissant un param√®tre de relaxation $\omega$ appropri√©, ce qui peut r√©duire le nombre d'it√©rations n√©cessaires pour atteindre la convergence. Nous constatons que pour des valeurs de $\omega$ proches de 1.5, la m√©thode PSOR converge plus rapidement que pour des valeurs plus proches de 1, ce qui sugg√®re que l'over-relaxation peut √™tre b√©n√©fique pour acc√©l√©rer la convergence de la m√©thode PSOR.

```{python}
# comparing time

omegas = [1.2, 1.5, 1.8, 1.9]

for omega in omegas:
    psor = PSOR(**params, payoff=1)
    start_time = time.time()
    U, t = psor.solve(omega=omega)
    end_time = time.time()
    print(f"Omega: {omega}, Time taken: {end_time - start_time:.4f} seconds")
```

### Semi-smooth Newton's method

En g√©n√©ral, la m√©thode PSOR est une m√©thode efficace pour r√©soudre les probl√®mes d'obstacle associ√©s aux options am√©ricaines, mais elle peut √™tre moins rapide que les m√©thodes de type Newton pour des probl√®mes de grande taille ou pour des sch√©mas d'ordre sup√©rieur.

Pour ce faire, nous avons impl√©ment√© une m√©thode de type Newton pour r√©soudre le probl√®me d'obstacle √† chaque pas de temps. Cette m√©thode consiste √† lin√©ariser le probl√®me d'obstacle autour d'une solution approximative √† chaque it√©ration, et √† r√©soudre le probl√®me lin√©aris√© pour obtenir une nouvelle approximation.

```{python}
params['J'] = 100 -1
params['N'] = 10


print("Param√®tres financiers:")
print("r=%.2f" %r_, "sigma=%.2f" %sigma_, "K=%.0f" %K_, "T=%.0f" %T_)

print("Param√®tres num√©riques:")
print("J=%.0f" %params['J'], "N=%.0f" %params['N'])
```

```{python}
newtonss = NewtonSemiSmooth(**params, payoff=1)
U,t = newtonss.solve()
s = newtonss.s
dt = newtonss.dt

plt.figure(figsize=(6, 5))
plt.plot(s,U,label="t=%.2f" %(t))
plt.plot(s,newtonss.phi(s), 'k--', label="payoff")
plt.xlabel("s")
plt.ylabel("u(t,s)")
plt.title("Evolution du prix du put europ√©en au cours du temps [Newton Semi-Smooth]")
plt.legend()
plt.show()
```

### Mini-conclusion sur les sch√©ma implicites

L‚Äô√©tude des sch√©mas implicites et semi-implicites montre que, lorsque le maillage spatial J et le pas temporel N sont raffin√©s, toutes les m√©thodes test√©es produisent des solutions num√©riques de plus en plus pr√©cises. Les ordres de convergence estim√©s (Œ±) sont coh√©rents avec les pr√©dictions th√©oriques : proches de 1 pour Euler implicite et proches de 2 pour Crank-Nicolson.

Le raffinement du maillage et du pas de temps s‚Äôaccompagne d‚Äôune augmentation notable du temps de calcul, ce que mettent en √©vidence les tables de convergence et qui illustre clairement le compromis entre pr√©cision et co√ªt computationnel.

En termes de qualit√© des solutions, les m√©thodes num√©riques explor√©es (PSOR et Newton semi-smooth) produisent des r√©sultats lisses et coh√©rents, respectant correctement la contrainte d‚Äôobstacle.

## Higher order schemes

Apr√®s avoir √©tudi√© les sch√©mas implicites classiques et les m√©thodes de r√©solution pour le probl√®me d‚Äôobstacle, nous consid√©rons √©galement un sch√©ma d‚Äôordre 2, le BDF2, qui am√©liore la pr√©cision temporelle tout en prenant en compte l‚Äôobstacle.

### BDF Scheme

Le sch√©ma BDF2 est test√© avec les m√™mes param√®tres de maillage spatial et de pas de temps que les sch√©mas pr√©c√©dents. Le graphique ci-dessous montre que le prix du put europ√©en reste lisse et coh√©rent, respectant correctement la contrainte d‚Äôobstacle, de mani√®re similaire aux autres m√©thodes implicites √©tudi√©es.

```{python}
params['J'] = 100 -1
params['N'] = 10

bdf2 = BdfScheme(**params, payoff=1)
U,t = bdf2.solve()
s = bdf2.s
dt = bdf2.dt

plt.figure(figsize=(6, 5))
plt.plot(s,U,label="t=%.2f" %(t))
plt.plot(s,bdf2.phi(s), 'k--', label="payoff")
plt.xlabel("s")
plt.ylabel("u(t,s)")
plt.title("Evolution du prix du put europ√©en au cours du temps [BDF2]")
plt.legend()
plt.show()
```

